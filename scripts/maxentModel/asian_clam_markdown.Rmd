---
title: "AsianClamMaxEnt"
author: "John Phelan and Chris Madsen"
date: "2024-10-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, warning = FALSE)

library(tidyverse)
library(ggplot2)
library(DBI)
library(bcinvadeR)
library(terra)
library(sf)
library(geodata)
library(predicts)
library(ggpubr)
library(dismo)
library(rJava)
#source("ZuurFuncs.R")
library(ecospat)
library(ENMeval)
library(bcmaps)
library(data.table)
library(here)

sppOI<-"asian clam"
regularisation_levels = c(1:5); feature_classes = c("L","LQ","LQH"); number_pseudoabsences<-1000
# The number of background points to be gnerated
number_pseudoabsences<-10000

habitat_threshold_var = "equal_training_sensitivity_and_specificity_cloglog_threshold"


#set locations
proj_wd = getwd()
onedrive_wd = paste0(str_extract(getwd(),"C:/Users/[A-Z]+/"),"OneDrive - Government of BC/data/")
onedrive_path = paste0(str_extract(getwd(),"C:/Users/[A-Z]+/"),"OneDrive - Government of BC/data/")

source(here("scripts/utils/prep_predictor_data_f.R"))
source(here("scripts/utils/run_maxent_f.R"))
source(here("scripts/utils/thin_occ.R"))

```

## R Markdown


```{r import_data}
bc<-bc_bound()
extentvect<- project(vect(bc),"EPSG:4326")
#extentvect<-terra::vect("./vect/fras_colum.gpkg")
extentvect<-project(extentvect, "EPSG:4326")
bc_vect = terra::vect(sf::st_transform(bcmaps::bc_bound(),4326))
bc_wgs<-sf::st_transform(bcmaps::bc_bound(),4326)

# ggplot() +
#   geom_sf(data = bc, fill = "lightblue") +
#   theme_minimal() +
#   labs(title = "British Columbia Geometry")


predictor_data = prep_predictor_data(proj_path = proj_wd,
                                     onedrive_path = paste0(onedrive_wd),
                                     extentvect)

predictor_data <- predictor_data[[c("pH", "calc","population_density", "elev",
                                    "TotalInspections", "days_fished", "Carbon_Dissolved_Organic", "Chlorophyll",  "Conductivity", "Oxygen_Dissolved", "Turbidity", 
                                    "temp_Summer", "temp_Winter", "Water_Temperature", "slope")]]

sppDF = bcinvadeR::grab_aq_occ_data(sppOI)

 # Ensure unique coordinates by adding
  sppDF_jitter = sppDF |>
    dplyr::filter(duplicated(paste0(geometry))) |>
    sf::st_jitter(factor = 0.0001)

  not_jittered_sppDF = sppDF |>
    dplyr::filter(!duplicated(paste0(geometry)))

  sppDF_j = dplyr::bind_rows(sppDF_jitter,
                                not_jittered_sppDF)
  
  dat = sppDF |> 
  dplyr::mutate(x = sf::st_coordinates(geometry)[,1],
                y = sf::st_coordinates(geometry)[,2])
species_name = dat$Species[1]

watercourses = terra::rast(paste0(onedrive_path,"fwa_streams/stream_order_three_plus_2km_res.tif")) 

predictor_data$TotalInspections<-subst(predictor_data$TotalInspections, NA, 0)
predictor_data$days_fished<-subst(predictor_data$days_fished, NA, 0)

watercourses<-crop(watercourses, extentvect)
watercourses<-mask(watercourses, extentvect)

plot(watercourses)
```

## Data Exploration



```{r data_exploration}

#thin_spp<-thin_occ(dat) # thins down the asian clam to one occurrence

for(raster_var in unique(names(predictor_data))){
  dat[[raster_var]] <- terra::extract(predictor_data[[raster_var]], 
                                        dat[,c("x","y")], ID = FALSE)[[raster_var]]
}

r_stack<-raster::stack(predictor_data)



datDT<-setDT(dat)

samp<- dat %>% 
    plyr::mutate(x = st_coordinates(geometry)[,1],
                     y = st_coordinates(geometry)[,2]) %>% 
    sf::st_drop_geometry() |> 
    dplyr::select(x,y) |> 
    mutate(present = 1)



```

### Plotting occurrences and predictors {.tabset}

#### Location of spp
The locations of the species across the provience. 
```{r map_location}

ggplot()+
  geom_sf(data = bc_wgs, color = "lightgrey", alpha = 0.7)+
  geom_point(data = samp, aes (x = x, y = y, color = as.factor(present)), size = 1.3)+
  scale_color_manual(values = c("0" = "purple", "1" = "darkgreen"),
                     labels = c("0" = "Absent", "1" = "Present"))+
  labs(color = paste0(sppOI))+
  ggtitle(paste0("Number of occurrences: ", nrow(samp)))+
  ggthemes::theme_map()+
  theme(plot.title = element_text(size = rel(2), face = "bold"),
        plot.subtitle = element_text(size = rel(1.8)),
        legend.title = element_text(size = rel(1.8)),
        legend.text = element_text(size = rel(1.2)),
        legend.position = 'bottom',
        panel.background = element_blank()
  ) 

```


#### Boxplots of predictors at presence locations
The values of the predictors in each raster are extracted at the locations of the occurrences. 
```{r boxplot}

melt_dat<-melt(datDT, id.vars = c(1:9), measure.vars = c(10:ncol(dat)))

ggplot(melt_dat, aes(x = 1, y = value)) +
  geom_boxplot() +
  facet_wrap(~ variable, scales = "free_y") +
  labs(title = "Boxplot of Values by Variable") +
  xlab("Variable") +
  ylab("Value")

```




## Colinearity

The dendogram is a visual representation of how correlated the predictor variables are. A user defined threshold is set, in this case to be 0.6 (medium). A smaller threshold will increase the correlation between the predictors.
```{r dendogram}
library(ENMTools)

cor<-raster.cor.matrix(predictor_data)
thresh<-0.6
dists<-as.dist(1-abs(cor))
clust <- hclust(dists, method = "single")
groups <- cutree(clust, h = 1 - thresh)
#jpeg("./images/cluterDendogram.jpg", width = 1200, height = 800)
## Visualize groups:
plot(clust, hang = -1)
rect.hclust(clust, h = 1 - thresh)
#dev.off()


```


The dendogram shows that total inspections and days fished are both correlated, as well as pH and calcium. We could consider removing these now, or running the model with all these predictors included. For the moment, I do not think that they should be removed as they may provide valuable information about suitable habitat. They should be removed after running the model with all predictors to assess their effect.

The variance inflation factor is another measures of the collinearity between variables.
```{r vif2}
vif2<-usdm::vif(predictor_data)
vif2
```
The higher the value of VIF, the more the predictor is colinear with another predictor. We cannot tell which predictors are colinear from these values, so the previous plot is more useful for this process. The values are sometimes requested or preferred so they have been included for completeness. 



## MaxEnt Model

Blocks are applied to separate the data. These are for validation and training the model fit. There are several options. The block selected accounts for spatial autocorrelation in the validation and training bins. The block splits occurrences (and background points) by latitude and longitude.

```{r setBlocks}

presences <- dplyr::distinct(samp)
pres_xy<-presences[,c("x", "y")]
pres<-st_as_sf(dat)
# Sample watercourses' locations for a collection of pseudoabsences; combine with data and then split into testing and training.
pseudoabsences <- predicts::backgroundSample(watercourses, p = terra::vect(pres), n = number_pseudoabsences, extf = 0.9) |> 
  as.data.frame()

the_block <- get.block(presences,bg=pseudoabsences, orientation = "lat_lon")
#table(the_block$occs.grp)

occs.z<- cbind(pres, raster::extract(r_stack, pres))
bg.z <- cbind(pseudoabsences, raster::extract(r_stack, pseudoabsences))

bg.z<-st_as_sf(bg.z, coords = c("x", "y"))

```

### Block partition plots

```{r plot_blocks}
evalplot.grps(pts = presences, pts.grp = the_block$occs.grp, envs = raster(predictor_data$pH))+
ggplot2::ggtitle("Spatial block partitions: occurrences")

evalplot.grps(pts = pseudoabsences, pts.grp = the_block$bg.grp, envs = raster(predictor_data$pH))+
  ggplot2::ggtitle("Spatial block partitions: background")



```

```{r similarity_plots}

crs(occs.z)
bg.z <- bg.z |> st_set_crs(st_crs(occs.z))
occs.z <- occs.z[c("pH"             ,          "calc"            ,         "population_density"    ,  
 "elev"      ,               "TotalInspections"        , "days_fished"      ,      
 "Carbon_Dissolved_Organic", "Chlorophyll"      ,       "Conductivity"      ,      
 "Oxygen_Dissolved"   ,      "Turbidity"       ,         "temp_Summer"    ,         
 "temp_Winter"   ,           "Water_Temperature")]

bg.z <- bg.z[c("pH"             ,          "calc"            ,         "population_density"    ,  
 "elev"      ,               "TotalInspections"        , "days_fished"      ,      
 "Carbon_Dissolved_Organic", "Chlorophyll"      ,       "Conductivity"      ,      
 "Oxygen_Dissolved"   ,      "Turbidity"       ,         "temp_Summer"    ,         
 "temp_Winter"   ,           "Water_Temperature")]

occs.z <- occs.z |> st_drop_geometry()
bg.z <- bg.z |> st_drop_geometry()


 # evalplot.envSim.hist(sim.type = "mess", ref.data = "pres", occs.z = occs.z, bg.z = bg.z,
 #                      occs.grp = the_block$occs.grp, bg.grp = the_block$bg.grp, categoricals = NULL)

 # evalplot.envSim.hist(sim.type = "most_diff", ref.data = "pres", occs.z = occs.z, bg.z = bg.z,
 #                      occs.grp = the_block$occs.grp, bg.grp = the_block$bg.grp, categoricals = NULL)

 # evalplot.envSim.hist(sim.type = "most_sim", ref.data = "pres", occs.z = occs.z, bg.z = bg.z,
 #                      occs.grp = the_block$occs.grp, bg.grp = the_block$bg.grp, categoricals = NULL)


 # evalplot.envSim.map(sim.type = "mess", ref.data = "pres", envs = r_stack, occs.z = occs.z,
 #                     bg.z = bg.z, occs.grp = the_block$occs.grp, bg.grp = the_block$bg.grp,
 #                     categoricals = NULL, bb.buf = 7)

 # evalplot.envSim.map(sim.type = "most_diff", ref.data = "pres", envs = r_stack, occs.z = occs.z,
 #                     bg.z = bg.z, occs.grp = the_block$occs.grp, bg.grp = the_block$bg.grp,
 #                    categoricals = NULL, bb.buf = 7)

```


### Presences vs background predictors

Data from the predictors were extracted at the presences and background points for the species. The values are dsiplated in a boxplot to examine what differences there may be between the two data for each predictor selected. 

```{r boxplot_bg_pres}

pres_box <- occs.z
pres_box$pres<-1
bg_box <- bg.z
bg_box$pres <- 0

tot_box <-rbind(pres_box, bg_box)
tot_box$index<- 1:nrow(tot_box)
tot_box<-setDT(tot_box)
melt_box<-melt(tot_box, id.vars = c("pres", "index"), measure.vars = c(1:(ncol(tot_box)-2)))


levels(melt_box$variable) <- c(
  "pH" = "pH",
  "calc" = "Calcium",
  "population_density" = "Population Density",
  "elev" = "Elevation",
  "TotalInspections" = "Total Inspections",
  "days_fished" = "Days Fished",
  "Carbon_Dissolved_Organic" = "Dissolved Organic Carbon",
  "Chlorophyll" = "Chlorophyll",
  "Conductivity" = "Conductivity",
  "Oxygen_Dissolved" = "Dissolved Oxygen",
  "Turbidity" = "Turbidity",
  "temp_Summer" = "Summer Temperature",
  "temp_Winter" = "Winter Temperature",
  "Water_Temperature" = "Water Temperature",
  "pres" = "Pressure"
)
melt_box$pres <- factor(melt_box$pres, levels = c(0, 1), labels = c("Absent", "Present"))


ggplot(melt_box, aes(x = as.factor(pres), y = value, fill = variable)) +
  geom_boxplot() +
  facet_wrap(~ variable, scales = "free_y") +
  labs(title = "Boxplot of Values by Variable") +
  ylab("Value")+
  theme_minimal()+
  theme(
    strip.text = element_text(size = 12, face = "bold"), 
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5), 
    axis.title = element_text(size = 14, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1, face = "bold")
  )

```




```{r run_model}

me = ENMevaluate(occs = pres_xy, 
                 envs = predictor_data, 
                 bg = pseudoabsences, 
                 algorithm = 'maxent.jar', 
                 partitions = 'block', 
                 tune.args = list(fc = feature_classes, 
                                  rm = regularisation_levels))
me@results


```

Running the model, there are combinations of the feature types: linear, quadraitic and hinge applied to the data. The regularisation parameter, ranging from 1 to 5 applies penalties to the model. Low values produce models with more features and predictors. There will be a trade-off between under- and over-fitting.

### Morans I / Schoeners D

This calculates the Schoeners D (or Morans I) for the fitted models. Values of Schoener's D that are closer to one indicate better overlap, with values tending to 0 are no overlap. This means that higher values in the table indicate more similar models.
```{r get_results}
overlap <- calc.niche.overlap(me@predictions, overlapStat = "D")
overlap

```

The performance statistics for the model describe the feature classes that were used (linear, quadratic or hinge) and the regularisation multiplier applied to the model. Tune.args is a unique identifier based on the feature classes and regularisation parameter. 

The AUC is the area under the curve for the training data. This value indicates how hte model has distinguished between the presences and background points on the training set. Higher scores indicate better fit here.

The CBI is the Boyce Index for the training data. This measures how well the model predictions align with the known occurrences. Higher values are indicative of better alignment between model predictions and observed distributions of occurrences.

auc.diff.avg and auc.diff.sd: The average and standard deviation of the difference between training and validation AUC. Smaller differences and lower variation between training and validation AUC scores indicate more stable performance, suggesting a balanced model that generalizes well.

Cross validation is completed on the models, where the occurrences sre split into a number of folds. The folds in this isntance are the blocks, described above.

auc.val.avg and auc.val.sd: Average and standard deviation of the AUC scores for the validation data, calculated across cross-validation runs. Higher auc.val.avg values indicate better generalization, while a lower auc.val.sd indicates that performance is consistent across subsets of the data.

cbi.val.avg and cbi.val.sd: Continuous Boyce Index values for the validation data. Similar to cbi.train, higher cbi.val.avg indicates a better match between predicted suitability and observed presences in validation data.

or.10p.avg and or.10p.sd: Average and standard deviation of the 10th percentile omission rate, which measures the model's ability to classify known presences accurately. A lower value here suggests a more accurate model.

or.mtp.avg and or.mtp.sd: The minimum training presence (MTP) omission rate. This shows how well the model performs using the strictest threshold, aiming to capture all known presences.

AICc: Corrected Akaike Information Criterion. Lower AICc values indicate better fit to the data with fewer parameters, balancing model fit with complexity. Here, delta.AICc shows the difference between the AICc of each model and the model with the lowest AICc, and w.AIC is the Akaike weight, indicating the relative likelihood of each model.

ncoef: The number of coefficients in the model. Higher values indicate greater model complexity.


```{r results_summary_stats}
# this gives the performance statistics for the whole set of models
me@results 

# and for the partitions. This is done by block - 4 of them
#me@results.partitions




# eval.algorithm(me)
# eval.tune.settings(me)
#eval.partition.method(me)
eval.results(me) 

eval.results.partitions(me)

eval.predictions(me)

```


```{r top_5}
top5 <- me@results |> 
  filter(!is.na(AICc)) |> 
  arrange(AICc, delta.AICc, desc(w.AIC)) |> 
  slice_head(n = 5)
top5
```

I have found the models with the lowest AICc. Delta AICc shows the difference between the top model and the others. The wAICc would sum to 1 for all the models. This is a normalised AICc that shows how likely one model is compared to another. 

While the "best" model is the first one on this list, with linear fits only and regularisation of 2. I would select the second model including quadratic features. Biologically, species may respond in a non-linear manner to temperature, dissolved oxygen, pH etc. The difference in AICc between the top two models is very small, which would suggest that the model fit will not be compromised by this choice.

```{r run_new_models}


model1_l = ENMevaluate(occs = pres_xy, 
                 envs = predictor_data, 
                 bg = pseudoabsences, 
                 algorithm = 'maxent.jar', 
                 partitions = 'block', 
                 tune.args = list(fc = "L", 
                                  rm = 2))
model1_l

model1_lq = ENMevaluate(occs = pres_xy, 
                 envs = predictor_data, 
                 bg = pseudoabsences, 
                 algorithm = 'maxent.jar', 
                 partitions = 'block', 
                 tune.args = list(fc = "LQ", 
                                  rm = 1))
model1_lq


```


```{r included_coeff}

model1_l@variable.importance$fc.L_rm.2 |> 
  mutate(percent.contribution = as.numeric(percent.contribution)) |> 
  #filter(percent.contribution > 0.0000000001) |> 
  arrange(desc(percent.contribution))

model1_lq@variable.importance$fc.LQ_rm.1 |> 
  mutate(percent.contribution = as.numeric(percent.contribution)) |> 
  #filter(percent.contribution > 0.0000000001) |> 
  arrange(desc(percent.contribution))

```


```{r compare_top}

plot(model1_l@predictions, main = paste0("Linear; regularisation: ", model1_l@results$rm, "; No. coefficients: ",
                                         model1_l@results$ncoef))

plot(model1_lq@predictions, main = paste0("Linear quadratic; regularisation: ", model1_lq@results$rm, "; No. coefficients:", model1_lq@results$ncoef))



```



```{r deeper_model}
# m1.mx <- eval.models(me)[["fc.LQH_rm.1"]]
# #m1.mx$betas
# 
# evalplot.stats(me, stats = "or.mtp", color = "fc", x.var = "rm")
```

```{r select_model}

# Find which model had the lowest AIC; we'll use this for now.
opt.aicc = eval.results(me) |> dplyr::filter(delta.AICc == 0)

opt.aicc

opt.seq <- opt.aicc %>% 
  filter(or.10p.avg == min(or.10p.avg)) %>% 
  filter(auc.val.avg == max(auc.val.avg))
opt.seq


mod.seq <- eval.models(me)[[opt.seq$tune.args]]
#mod.seq$betas
plot(mod.seq, type="cloglog")

pred.seq <- eval.predictions(me)[[opt.seq$tune.args]]
plot(pred.seq)
points(eval.bg(me), pch = 3, col = eval.bg.grp(me), cex = 0.5)
points(eval.occs(me), pch = 21, bg = eval.occs.grp(me))

mod.simple<-eval.models(me)[["fc.L_rm.5"]]
mod.complex <- eval.models(me)[['fc.LQH_rm.1']]
plot(mod.simple)
plot(mod.complex)




eval.predictions(me)[["fc.L_rm.5"]]
eval.occs(me)[["fc.L_rm.5"]]
eval.occs(me)[["fc.LQH_rm.1"]]
eval.variable.importance(me)[["fc.L_rm.5"]]
eval.models(me)[["fc.L_rm.5"]]

plot(eval.predictions(me)[['fc.L_rm.5']], 
     legend = FALSE, main = 'L_5 prediction')

plot(eval.predictions(me)[['fc.LQH_rm.1']], 
     legend = FALSE, main = 'LQH_1 prediction')




str(mod.simple)
mod.simple@results 



```


### Generate a null model
```{r null_model}

# mod.null <- ENMnulls(me, mod.settings = list(fc = "LQ", rm = 5), no.iter = 100)
# null.results(mod.null) %>% head()
# null.emp.results(mod.null)
# evalplot.nulls(mod.null, stats = c("or.10p", "auc.val"), plot.type = "histogram")
# evalplot.nulls(mod.null, stats = c("or.10p", "auc.val"), plot.type = "violin")
```



